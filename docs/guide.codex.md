# 바이브 코딩 가이드

## 1. 이 문서의 목적
- 빠르게 변화하는 AI 코딩 도구 환경에서 개발자들이 일관된 품질과 생산성을 유지할 수 있도록 돕는 것이 최우선 목표다.
- 문서는 살아있는 표준이며, 주요 변경사항은 Git 태그를 통해 버전 관리한다. 팀은 태그를 기준으로 동일한 가이드를 참조해야 한다.
- 내용은 실제 프로젝트의 피드백을 반영하여 주기적으로 검증·개선한다.

## 2. 바이브 코딩의 정의
- 바이브 코딩은 단순한 자연어 코드 생성이 아니라, AI 도구 전반을 활용해 설계·구현·검증 프로세스를 가속화하는 전방위 개발 방법론이다.
- 목표는 개발자가 문제 정의, 가설 수립, 검증 루프를 짧게 가져가도록 돕는 것이다. 코드 작성 자체보다 시스템 사고와 의사결정 자동화를 강화한다.

## 3. 핵심 원칙
1. **기존 소프트웨어 공학의 연속선**
   - SOLID, TDD, 디자인 패턴, 애자일, 데브옵스 등 기존 방법론이 여전히 유효하다. 다만 AI를 통해 실행 비용이 낮아질 뿐이다.
2. **모던 소프트웨어 엔지니어링 정신 계승**
   - Dave Farley가 제시한 모던 소프트웨어 엔지니어링 활동(https://www.davefarley.net/?p=352)을 더 적은 비용으로, 더 자주 반복 가능하도록 AI를 활용한다.
3. **신뢰할 수 있는 프로세스 구축**
   - AI 결과물 자체보다 결과를 검증하는 인간 주도 프로세스(테스트, 리뷰, 백업)를 설계한다. "AI를 믿지 말라, 사람도 믿지 말라"는 관점에서 자동 검사 체계를 확보한다.
4. **생산성 증폭 공식**
   - `바이브 코딩 생산성 = 개발자 역량 × AI 도구와 프로세스의 생산성`
   - 개발자 역량(문제 해결력, 도메인 이해, 아키텍처 설계, 프로세스·보안 지식)이 낮으면 AI 도구 효용도 제한된다. 역량이 높을수록 AI가 생산성을 증폭시킨다.
5. **미래 대비 역량 구성**
   - 순수 코딩 능력의 중요도는 감소하고 있으며, 문제 정의 능력과 시스템 설계 역량 비중이 커지고 있다. 프로그래밍 언어를 직접 다루지 않는 개발 환경을 대비한다.

## 4. 도구
### 4.1 AI 코딩 도구 선정
- Claude(모델)와 Claude Code(도구)가 종합 역량과 업데이트 속도면에서 우위에 있다. 현재 기준 경쟁자 대비 약 6개월 정도 앞서 있으나, 격차가 고정되어 있지 않으므로 분기마다 재평가한다.
- 재평가 체크리스트: 모델 품질(추론력·안정성), 편집 경험, 협업 기능, 보안·프라이버시 옵션, 비용.
- 주력 도구 외에도 Cursor, GitHub Copilot 등 대체 도구를 파일럿하여 특정 사용 사례(예: 코드 변환, 정적 분석)에 최적화된 옵션을 찾는다.

### 4.2 프로그래밍 언어 및 스택
- 백엔드 중심 팀의 기본 선택지는 TypeScript/Node.js, Python, Go 등을 포함한다. 도구가 제안한 코드를 신뢰하기 전에 언어별 베스트 프랙티스를 명확히 정의한다.
- 언어별 템플릿(프로젝트 구조, 테스트 스캐폴딩, 린터 설정)을 저장소에 두고 AI에게도 동일한 템플릿을 지침으로 제공한다.
- 새로운 언어나 프레임워크를 도입할 때는 PoC→파일럿→확산 단계를 밟고, AI 프롬프트와 코드리뷰 체크리스트를 함께 갱신한다.

## 5. 프롬프팅
- 요구사항과 의도를 함께 전달한다. XY 문제처럼 진짜 니즈를 처음부터 공유하면 모델이 더 적확한 솔루션을 제안한다.
- AI에게 질문을 허용하고, 명확화 질문을 받을 수 있도록 "필요하면 질문하라"는 지시를 기본 프롬프트에 포함한다. Anthropic 엔지니어가 제시한 방법론(https://x.com/trq212/status/2005315275026260309)을 기본 루틴으로 삼는다.
- 반복되는 프롬프트는 Claude Code의 에이전트·커맨드·훅·스킬 시스템을 사용해 관리한다. 프롬프트 자산은 레포지토리에서 버전 관리하여 팀 전원이 동일한 명령어를 활용하도록 한다.
- 프롬프트 품질 측정 지표(예: 해결까지 걸린 턴, 재작성 횟수)를 수집해 개선한다.

## 6. 워크플로우
1. **요구사항 분석**
   - 사용자 시나리오, 제약, 성공 기준을 문서화하고 AI에게도 동일한 컨텍스트를 제공한다.
2. **테크 스택 및 아키텍처 설계**
   - 후보 아키텍처를 AI와 브레인스토밍하고, 핵심 결정(데이터 모델, 확장 전략)을 Gardner Decision Log 형태로 기록한다.
3. **계획 수립**
   - 일을 가능한 작은 배치로 쪼개고 "확인 가능한 단위"를 정의한다. 각 단위에 대해 명시적인 입력·출력·검증 방법을 지정한다.
4. **실행 루프**
   - (프롬프트 → 코드 생성 → 테스트 → 리뷰 → 배포) 단계를 반복하며, 단계 사이의 대기 시간을 최소화하도록 자동화를 추가한다.

## 7. 품질 관리
- 기능을 확인 가능한 단위로 나누고, 생성과 테스트를 동시에 진행한다. 각 단위마다 최소 한 개의 자동화 테스트를 강제한다.
- 테스트 전략: 단위 테스트(생성된 코드 검증), 스냅샷 테스트(AI 생성 UI/문서 검증), 계약 테스트(API 호환성)로 구성한다.
- 모든 변경은 자동화된 테스트와 CI 파이프라인을 통과해야 한다. 실패 시 로그·프롬프트를 함께 기록해 AI 응답 개선에 활용한다.
- 코드 리뷰 시 체크리스트: 보안 취약점, 데이터 흐름, 예외 처리, 프롬프트 지속 가능성(자산화 여부).

## 8. 보안
- 가능한 경우 ZDR(Zero Data Retention) 모드를 기본값으로 설정한다. 데이터를 외부로 보낼 때는 민감도 라벨링과 마스킹 정책을 따른다.
- 보안 리뷰 자동화를 위해 SAST/DAST 도구와 AI 기반 코드 스캐너를 CI에 통합한다.
- 모델 프롬프트에 보안 정책을 명시하고, 생성된 코드가 정책을 위반할 경우 자동으로 플래그하는 룰을 둔다.

## 9. 협업
- 바이브 코딩 시대에는 소유권 개념을 재정의한다. "프롬프트·프로세스·자동화"가 주요 자산임을 명시하고, 개인이 아닌 팀 소유로 관리한다.
- 프롬프트와 프로세스는 저장소나 Claude 플러그인으로 공유해 팀 전원이 동일한 세팅을 사용하도록 한다.
- 사내 바이브 코딩 커뮤니티를 운영하여 베스트 프랙티스를 발견 즉시 전파하고, 실패 사례도 기록한다.
- 페어/몹 프로그래밍을 통해 프롬프트 설계와 리뷰를 공동으로 진행한다. 세션 로그는 지식 베이스에 보관한다.

## 10. 팁 & 유용한 리소스
- Anthropic 공식 문서, 튜토리얼, 기술 블로그를 주기적으로 확인해 최신 기능과 한계를 파악한다.
- Reddit의 r/Anthropic 포럼, 긱뉴스(https://news.hada.io/) 등 커뮤니티를 모니터링하여 외부 인사이트를 흡수한다.
- Flask 개발자 Armin Ronacher, Claude Code 개발자 Boris Cherny 등의 트위터·유튜브·블로그를 팔로우해 프롬프트·도구 활용 노하우를 확보한다.
- 팀 위키에 정기적으로 링크와 학습 노트를 정리해 신규 팀원이 빠르게 온보딩하도록 지원한다.
